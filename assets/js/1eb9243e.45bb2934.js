"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[4320],{3905:(e,n,a)=>{a.d(n,{Zo:()=>p,kt:()=>c});var t=a(7294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function o(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function s(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?o(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function i(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},o=Object.keys(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=t.createContext({}),u=function(e){var n=t.useContext(l),a=n;return e&&(a="function"==typeof e?e(n):s(s({},n),e)),a},p=function(e){var n=u(e.components);return t.createElement(l.Provider,{value:n},e.children)},d={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},m=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),m=u(a),c=r,k=m["".concat(l,".").concat(c)]||m[c]||d[c]||o;return a?t.createElement(k,s(s({ref:n},p),{},{components:a})):t.createElement(k,s({ref:n},p))}));function c(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=a.length,s=new Array(o);s[0]=m;var i={};for(var l in n)hasOwnProperty.call(n,l)&&(i[l]=n[l]);i.originalType=e,i.mdxType="string"==typeof e?e:r,s[1]=i;for(var u=2;u<o;u++)s[u]=a[u];return t.createElement.apply(null,s)}return t.createElement.apply(null,a)}m.displayName="MDXCreateElement"},8041:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>u});var t=a(7462),r=(a(7294),a(3905));const o={sidebar_position:2,sidebar_label:"Web API"},s="Administration Web API",i={unversionedId:"guides/admin/web-api",id:"guides/admin/web-api",title:"Administration Web API",description:"In this section, we will learn how to configure the Administration Web API.",source:"@site/docs/guides/admin/web-api.md",sourceDirName:"guides/admin",slug:"/guides/admin/web-api",permalink:"/kafkaflow/docs/guides/admin/web-api",draft:!1,editUrl:"https://github.com/farfetch/kafkaflow/tree/master/website/docs/guides/admin/web-api.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,sidebar_label:"Web API"},sidebar:"tutorialSidebar",previous:{title:"Administration",permalink:"/kafkaflow/docs/guides/admin/"},next:{title:"Dashboard",permalink:"/kafkaflow/docs/guides/admin/dashboard"}},l={},u=[{value:"Adding the Admin API",id:"adding-the-admin-api",level:2},{value:"Adding Swagger to Admin API",id:"swagger",level:2},{value:"API Endpoints",id:"api-endpoints",level:2},{value:"Consumers",id:"consumers",level:3},{value:"Pause",id:"pause",level:4},{value:"Resume",id:"resume",level:4},{value:"Restart",id:"restart",level:4},{value:"Reset Offsets",id:"reset-offsets",level:4},{value:"Rewind Offsets",id:"rewind-offsets",level:4},{value:"Change the Number of Workers\u200b",id:"change-the-number-of-workers",level:4},{value:"Consumer Group",id:"consumer-group",level:3},{value:"Pause",id:"pause-1",level:4},{value:"Resume",id:"resume-1",level:4}],p={toc:u};function d(e){let{components:n,...a}=e;return(0,r.kt)("wrapper",(0,t.Z)({},p,a,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"administration-web-api"},"Administration Web API"),(0,r.kt)("p",null,"In this section, we will learn how to configure the Administration Web API."),(0,r.kt)("p",null,"You can configure KafkaFlow to expose an API for administrative operations."),(0,r.kt)("p",null,"The API can be used either manually (for example, you can install and use ",(0,r.kt)("a",{parentName:"p",href:"#swagger"},"Swagger"),") or by any other application using the available endpoints. "),(0,r.kt)("p",null,"Furthermore, you can execute the operations publishing commands directly to the KafkaFlow admin topics using the class ",(0,r.kt)("inlineCode",{parentName:"p"},"AdminProducer"),"."),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"It is important to note that these operations will be executed on all application instances. If you have 10 machines running your application, ",(0,r.kt)("strong",{parentName:"p"},"one single POST")," to pause a specific consumer will pause it in ",(0,r.kt)("strong",{parentName:"p"},"all")," the machines.")),(0,r.kt)("h2",{id:"adding-the-admin-api"},"Adding the Admin API"),(0,r.kt)("p",null,"Install the following packages:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.nuget.org/packages/KafkaFlow.Admin/"},"KafkaFlow.Admin")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.nuget.org/packages/KafkaFlow.Admin.WebApi/"},"KafkaFlow.Admin.WebApi"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"dotnet add package KafkaFlow.Microsoft.DependencyInjection\ndotnet add package KafkaFlow.Admin\ndotnet add package KafkaFlow.Admin.WebApi\n")),(0,r.kt)("p",null,"You can configure the API during the ",(0,r.kt)("a",{parentName:"p",href:"../configuration"},"configuration")," by enabling Admin Messages on the Cluster configuration, as shown in the following example (",(0,r.kt)("em",{parentName:"p"},"built using .NET 6"),")."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},'using KafkaFlow;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services\n    .AddKafka(kafka => kafka\n        .AddCluster(cluster => cluster\n            .WithBrokers(new[] { "localhost:9092" })\n            .AddConsumer(consumer => consumer\n                .Topic("mytopic")\n                .WithGroupId("g1")\n                .WithWorkersCount(1)\n                .WithBufferSize(10)\n            )\n            .EnableAdminMessages(\n                "kafka-flow.admin" // the admin topic\n            )\n        ))\n    .AddControllers();\n\nvar app = builder.Build();\n\napp.MapControllers();\n\nvar kafkaBus = app.Services.CreateKafkaBus();\nawait kafkaBus.StartAsync();\n\nawait app.RunAsync();\n')),(0,r.kt)("p",null,"The API will be accessed on ",(0,r.kt)("inlineCode",{parentName:"p"},"/kafka-flow/"),"."),(0,r.kt)("h2",{id:"swagger"},"Adding Swagger to Admin API"),(0,r.kt)("p",null,"It's possible to generate a ",(0,r.kt)("a",{parentName:"p",href:"https://swagger.io/"},"Swagger")," interface for documentation and as UI to explore and test operations."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"This is not a KafkaFlow feature. This guide works as a starting guide on how to configure it using ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/domaindrivendev/Swashbuckle.AspNetCore"},"Swashbuckle"),".\nFor advanced information on it, go to Swashbuckle documentation.")),(0,r.kt)("p",null,"Install Swashbuckle package."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"dotnet add package Swashbuckle.AspNetCore\n")),(0,r.kt)("p",null,"Register the Swagger Generator on the services configuration."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},'using Microsoft.OpenApi.Models;\n\nbuilder.Services\n    .AddSwaggerGen(\n        c =>\n        {\n            c.SwaggerDoc(\n                "kafka-flow",\n                new OpenApiInfo\n                {\n                    Title = "KafkaFlow Admin",\n                    Version = "kafka-flow",\n                });\n        });\n')),(0,r.kt)("p",null,"Expose the generated documentation."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'app.UseSwagger();\napp.UseSwaggerUI(c =>\n{\n    c.SwaggerEndpoint("/swagger/kafka-flow/swagger.json", "KafkaFlow Admin");\n});\n')),(0,r.kt)("p",null,"Swagger UI will be accessed on ",(0,r.kt)("inlineCode",{parentName:"p"},"/swagger/"),"."),(0,r.kt)("h2",{id:"api-endpoints"},"API Endpoints"),(0,r.kt)("p",null,(0,r.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/233064/98698756-5129ca00-236e-11eb-9a70-e0f997050cd6.jpg",alt:"admin-swagger-1"})),(0,r.kt)("h3",{id:"consumers"},"Consumers"),(0,r.kt)("h4",{id:"pause"},"Pause"),(0,r.kt)("p",null,"Pause all Kafka consumers based on their name and groupId."),(0,r.kt)("p",null,"Endpoint"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"POST /kafka-flow/groups/{groupId}/consumers/{consumerName}/pause")),(0,r.kt)("p",null,"Command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},"var adminProducer = provider.GetService<IAdminProducer>();\nadminProducer.ProduceAsync(new PauseConsumerByName { ConsumerName = consumerName });\n")),(0,r.kt)("h4",{id:"resume"},"Resume"),(0,r.kt)("p",null,"Resume all Kafka consumers based on their name and groupId."),(0,r.kt)("p",null,"Endpoint"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"POST /kafka-flow/groups/{groupId}/consumers/{consumerName}/resume")),(0,r.kt)("p",null,"Command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},"var adminProducer = provider.GetService<IAdminProducer>();\nadminProducer.ProduceAsync(new ResumeConsumerByName{ ConsumerName = consumerName });\n")),(0,r.kt)("h4",{id:"restart"},"Restart"),(0,r.kt)("p",null,"Restart all Kafka consumers based on their name and groupId. This operation will not change any offsets, it's a simple restart. The internal Confluent Consumer will be recreated. This operation causes a partition rebalanced between the consumers."),(0,r.kt)("p",null,"Endpoint"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"POST /kafka-flow/groups/{groupId}/consumers/{consumerName}/restart")),(0,r.kt)("p",null,"Command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},'var adminProducer = provider.GetService<IAdminProducer>();\nadminProducer.ProduceAsync(new RestartConsumerByName{ ConsumerName = "consumerName" });\n')),(0,r.kt)("h4",{id:"reset-offsets"},"Reset Offsets"),(0,r.kt)("p",null,"Reset the offset of all topics listening by the Kafka consumers with the name and groupId informed. To achieve this, KafkaFlow needs to stop the consumers, search for the lowest offset value in each topic/partition, commit these offsets, and restart the consumers. This operation causes a rebalance between the consumers. ",(0,r.kt)("strong",{parentName:"p"}," All topic messages will be reprocessed ")),(0,r.kt)("p",null,"Endpoint"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"POST /kafka-flow/groups/{groupId}/consumers/{consumerName}/reset-offsets")),(0,r.kt)("p",null,"Command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},'var adminProducer = provider.GetService<IAdminProducer>();\nadminProducer.ProduceAsync(new ResetConsumerOffset{ ConsumerName = "consumerName" });\n')),(0,r.kt)("h4",{id:"rewind-offsets"},"Rewind Offsets"),(0,r.kt)("p",null,"Rewind the offset of all topics listening by a Kafka consumer with its name and groupId. To achieve this, KafkaFlow needs to stop the consumers, search for the first offset before the DateTime informed, commit the new offsets, and restart the consumers. This operation causes a rebalance between the consumers."),(0,r.kt)("p",null,"Endpoint"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'POST /kafka-flow/groups/{groupId}/consumers/{consumerName}/rewind-offsets-to-date\n\nBODY\n{\n  "date": "2000-11-09T17:52:54.547Z"\n}\n \n')),(0,r.kt)("p",null,"Command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},'var adminProducer = provider.GetService<IAdminProducer>();\nadminProducer.ProduceAsync(new RewindConsumerOffsetToDateTime\n{ \n   ConsumerName = "consumerName",\n   DateTime = DateTime.Now\n});\n')),(0,r.kt)("h4",{id:"change-the-number-of-workers"},"Change the Number of Workers\u200b"),(0,r.kt)("p",null,"Change the numbers of workers (degree of parallelism) for the KafkaFlow consumer with the name and groupId informed. This operation causes a rebalance between the consumers."),(0,r.kt)("p",null,"Endpoint"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'POST /kafka-flow/groups/{groupId}/consumers/{consumerName}/change-worker-count\n\nBODY\n{\n  "workerCount": 0\n}\n \n')),(0,r.kt)("p",null,"Command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},'var adminProducer = provider.GetService<IAdminProducer>();\nadminProducer.ProduceAsync(new ChangeConsumerWorkerCount\n{ \n   ConsumerName = "consumerName",\n   WorkerCount = 100\n});\n')),(0,r.kt)("h3",{id:"consumer-group"},"Consumer Group"),(0,r.kt)("h4",{id:"pause-1"},"Pause"),(0,r.kt)("p",null,"Pause all Kafka consumers based on their groupId."),(0,r.kt)("p",null,"Endpoint"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"POST /kafka-flow/groups/{groupId}/pause")),(0,r.kt)("p",null,"Command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},'var adminProducer = provider.GetService<IAdminProducer>();\nadminProducer.ProduceAsync(new PauseConsumersByGroup{ GroupId = "groupId"});\n')),(0,r.kt)("h4",{id:"resume-1"},"Resume"),(0,r.kt)("p",null,"Resume all Kafka consumers based on groupId."),(0,r.kt)("p",null,"Endpoint"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"POST /kafka-flow/groups/{groupId}/resume")),(0,r.kt)("p",null,"Command"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},'var adminProducer = provider.GetService<IAdminProducer>();\nadminProducer.ProduceAsync(new ResumeConsumersByGroup{ GroupId = "groupId"});\n')))}d.isMDXComponent=!0}}]);